"""
Script Ä‘á»ƒ verify ráº±ng transformer connections Ä‘ang há»c Ä‘Æ°á»£c
Cháº¡y script nÃ y sau khi training 1 epoch Ä‘á»ƒ kiá»ƒm tra
"""

import torch
import re
import sys

def check_training_log(log_path):
    """Kiá»ƒm tra log file Ä‘á»ƒ verify transformer learning"""
    print("=" * 80)
    print("VERIFYING TRANSFORMER LEARNING FROM LOG")
    print("=" * 80)
    
    with open(log_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # TÃ¬m táº¥t cáº£ TransON values
    trans_on_pattern = r"TransON: \[(.*?)\]"
    matches = re.findall(trans_on_pattern, content)
    
    if not matches:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y TransON trong log!")
        return False
    
    print(f"\nğŸ“Š TÃ¬m tháº¥y {len(matches)} epochs vá»›i TransON data\n")
    
    # Parse cÃ¡c giÃ¡ trá»‹
    epochs_data = []
    for i, match in enumerate(matches[:min(20, len(matches))]):  # Láº¥y 20 epochs Ä‘áº§u
        values = [float(v.strip().strip("'")) for v in match.split(',')]
        epochs_data.append((i, values))
        print(f"Epoch {i:2d}: {[f'{v:.4f}' for v in values]}")
    
    # Kiá»ƒm tra xem cÃ³ thay Ä‘á»•i khÃ´ng
    print("\n" + "=" * 80)
    print("PHÃ‚N TÃCH Káº¾T QUáº¢")
    print("=" * 80)
    
    if len(epochs_data) < 2:
        print("âš ï¸  ChÆ°a Ä‘á»§ data Ä‘á»ƒ phÃ¢n tÃ­ch (cáº§n Ã­t nháº¥t 2 epochs)")
        return False
    
    first_epoch = epochs_data[0][1]
    last_epoch = epochs_data[-1][1]
    
    # TÃ­nh Ä‘á»™ thay Ä‘á»•i
    max_change = max(abs(first_epoch[i] - last_epoch[i]) for i in range(len(first_epoch)))
    
    print(f"\nğŸ” GiÃ¡ trá»‹ Ä‘áº§u tiÃªn (Epoch 0): {[f'{v:.4f}' for v in first_epoch]}")
    print(f"ğŸ” GiÃ¡ trá»‹ cuá»‘i cÃ¹ng (Epoch {len(epochs_data)-1}): {[f'{v:.4f}' for v in last_epoch]}")
    print(f"\nğŸ“ˆ Äá»™ thay Ä‘á»•i lá»›n nháº¥t: {max_change:.6f}")
    
    # ÄÃ¡nh giÃ¡
    if max_change < 0.001:
        print("\nâŒ THáº¤T Báº I: GiÃ¡ trá»‹ háº§u nhÆ° khÃ´ng Ä‘á»•i!")
        print("   â†’ Transformer connections CHÆ¯A há»c Ä‘Æ°á»£c")
        print("   â†’ Vui lÃ²ng kiá»ƒm tra láº¡i code cÃ³ a_loss.backward()")
        return False
    elif max_change < 0.01:
        print("\nâš ï¸  Cáº¢NH BÃO: GiÃ¡ trá»‹ thay Ä‘á»•i ráº¥t nhá»")
        print("   â†’ CÃ³ thá»ƒ learning rate quÃ¡ tháº¥p")
        print("   â†’ Hoáº·c cáº§n training thÃªm epochs")
        return True
    else:
        print("\nâœ… THÃ€NH CÃ”NG: Transformer connections Ä‘ang há»c!")
        print("   â†’ GiÃ¡ trá»‹ thay Ä‘á»•i theo thá»i gian")
        print("   â†’ Fix Ä‘Ã£ hoáº¡t Ä‘á»™ng Ä‘Ãºng!")
        return True

def check_gradient_in_code():
    """Kiá»ƒm tra code cÃ³ a_loss.backward() khÃ´ng"""
    print("\n" + "=" * 80)
    print("CHECKING CODE FOR FIXES")
    print("=" * 80)
    
    train_file = "hct_net/train_CVCDataset.py"
    
    try:
        with open(train_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Check 1: a_loss.backward()
        if "a_loss.backward()" in content:
            print("âœ… Found: a_loss.backward()")
        else:
            print("âŒ MISSING: a_loss.backward()")
            print("   â†’ Cáº§n thÃªm a_loss.backward() trÆ°á»›c optimizer_arch.step()")
        
        # Check 2: alphas_transformer_connections.grad initialization
        if "alphas_transformer_connections.grad = torch.zeros_like" in content:
            print("âœ… Found: alphas_transformer_connections.grad initialization")
        else:
            print("âŒ MISSING: alphas_transformer_connections.grad initialization")
            print("   â†’ Cáº§n thÃªm gradient initialization cho transformer alphas")
        
        # Check 3: transformer_loss in a_loss computation
        if "transformer_loss" in content and "a_loss = a_loss +" in content:
            print("âœ… Found: transformer_loss Ä‘Æ°á»£c thÃªm vÃ o a_loss")
        else:
            print("âš ï¸  WARNING: transformer_loss cÃ³ thá»ƒ chÆ°a Ä‘Æ°á»£c thÃªm vÃ o a_loss")
        
    except FileNotFoundError:
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file: {train_file}")
        return False
    
    return True

def main():
    print("\n" + "=" * 80)
    print(" TRANSFORMER LEARNING VERIFICATION TOOL")
    print("=" * 80)
    
    # Check code
    code_ok = check_gradient_in_code()
    
    # Check log náº¿u cÃ³
    if len(sys.argv) > 1:
        log_path = sys.argv[1]
        print(f"\nğŸ“ Checking log file: {log_path}")
        log_ok = check_training_log(log_path)
        
        print("\n" + "=" * 80)
        print("FINAL VERDICT")
        print("=" * 80)
        
        if code_ok and log_ok:
            print("âœ… âœ… âœ…  ALL CHECKS PASSED!")
            print("Transformer connections Ä‘ang há»c Ä‘Ãºng cÃ¡ch!")
        elif code_ok and not log_ok:
            print("âš ï¸  Code Ä‘Ã£ Ä‘Æ°á»£c fix nhÆ°ng training chÆ°a thÃ nh cÃ´ng")
            print("HÃ£y training thÃªm vÃ i epochs vÃ  kiá»ƒm tra láº¡i")
        else:
            print("âŒ Váº«n cÃ²n váº¥n Ä‘á» cáº§n fix!")
            print("Vui lÃ²ng xem hÆ°á»›ng dáº«n trong BUG_FIX_TRANSFORMER_LEARNING.md")
    else:
        print("\nğŸ’¡ Tip: Cháº¡y vá»›i log file Ä‘á»ƒ kiá»ƒm tra káº¿t quáº£ training:")
        print("   python verify_fix.py path/to/run.log")

if __name__ == "__main__":
    main()
